{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12837d4-a635-4517-b627-41deac88bfe5",
   "metadata": {},
   "source": [
    "# NeRF - Neural Radiance Fields\n",
    "<table><tr>\n",
    "<td> <img src=\"assets/nerf-paper-head.png\" /> </td>\n",
    "<td> <img src=\"assets/its-nerf.gif\" /> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c96f964-74e4-482b-be9c-1250552cbb87",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Campos\n",
    "\n",
    "![alt text](assets/what-neural-fields2.png \"what are neural fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180ec783-5496-45b2-bef8-f23acc37a046",
   "metadata": {},
   "source": [
    "### Campos Neuronales\n",
    "\n",
    "Campos generados con redes neuronales cuyo input esta compredido por magnitudes que representan coordenadas en el espacio y/o tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f07503f-10ac-419d-aa02-45e1412b5781",
   "metadata": {},
   "source": [
    "![alt text](assets/what-neural-fields.PNG \"what are neural fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ab92a5-1197-4525-92b1-b0b3eab1f486",
   "metadata": {},
   "source": [
    "## Aplicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cadc69-322f-46a0-a492-0c876927020d",
   "metadata": {},
   "source": [
    "Han obtenido éxito en problemas como la síntesis de imágenes y formas en 3D, la animación de cuerpos humanos, la reconstrucción en 3D y la estimación de poses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ff9c6e-cc96-4191-8fb6-19e8399fe2c8",
   "metadata": {},
   "source": [
    "![alt text](assets/neural-fields-apps.png \"aplicaciones de neural fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65baa74e-db1e-4a62-b059-fc00e50210b7",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/neural-fields-papers-stats.PNG\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dbe58f-fe07-4c13-ac73-7be0f14d7624",
   "metadata": {},
   "source": [
    "## NeRF - Neural Radiance Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9544f07-554a-49c7-8c05-978871b0ce54",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/nerf-output-example.gif\"/></center>\n",
    "El objetivo de NERF es generar imágenes de alta calidad a partir de la pose del observador (la cámara). Con NeRF controlamos explícitamente la pose del observador para obtener imágenes renderizadas acorde a esa pose. \n",
    "\n",
    "El modelo entrenado con una cantidad discreta de imagenes aprende una función de escena volumétrica continua que puede asignar una densidad de color y volumen a cualquier voxel en el espacio. Los pesos de la red están optimizados para codificar la representación de la escena permitiendo que el modelo pueda generar fácilmente nuevas visualizaciones desde cualquier punto del espacio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b8f110-ca81-4e30-8e0b-192f284febdd",
   "metadata": {},
   "source": [
    "## 1era etapa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7784c185-7829-4793-89c3-99def0811146",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/input-output.PNG\"/></center>\n",
    "<center><img src=\"assets/input-output2.PNG\"/></center>\n",
    "<center><img src=\"assets/parametric-equation.PNG\"/></center>\n",
    "<center><img src=\"assets/nerf-poses.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f5d97-dcad-4769-a112-9ce988daa969",
   "metadata": {},
   "source": [
    "## 2da etapa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86419f4a-3da5-455b-8c1c-ece94c3c904e",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/input_output_2.PNG\"/></center>\n",
    "\n",
    "## <center>Hierarchical volume sampling</center>\n",
    "\n",
    "<center><img src=\"assets/nerf-query.PNG\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f175b92-8677-4d47-a632-fbc3b1123533",
   "metadata": {},
   "source": [
    "## 3era etapa - Encoding de posiciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa915c-7715-440a-a560-c9539e7e0709",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/input_output_3.PNG\"/></center>\n",
    "<center><img src=\"assets/position-encoding-compare.PNG\"/></center>\n",
    "<center><img src=\"assets/position-encoding-sample.PNG\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d7592-d522-41f4-973d-965f25a6d22a",
   "metadata": {},
   "source": [
    "## 4ta etapa - Inferencia con MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e522c88-30d0-4fe9-96a4-3ab2d8d9e48a",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/input_output_4.PNG\"/></center>\n",
    "<center><img src=\"assets/MLP.png\"/></center>\n",
    "<center><img src=\"assets/MLP-output.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7238dd0-2ada-4951-9b11-dd48c969242e",
   "metadata": {},
   "source": [
    "## Volume rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758efab6-58a8-478f-b206-6ac7382b8a2a",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/input_output_volume.png\"/></center>\n",
    "\n",
    " ### <center> Ray marching algorithm + rendering equation</center>\n",
    "<center><img src=\"assets/voldev-backward-raymarching.gif\"/></center>\n",
    "Se calcula la suma de todos los valores RGB de todos los puntos a lo largo del rayo, ponderados por la probabilidad de que el rayo se detenga en cualquier punto dado cuando vuela desde el observador hacia la escena. Cuanto mayor sea la densidad de volumen del punto, mayor será la probabilidad de que el rayo se detenga en ese punto y, por lo tanto, la probabilidad de que el valor RGB de ese punto tenga un impacto significativo en el archivo RGB final del píxel renderizado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68893ff-9177-4275-9156-ce074bcdd0d9",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d569c4-efcf-4645-ae92-dc9902563fb3",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/input_output_loss.png\"/></center>\n",
    "<center><img src=\"assets/render-loss.gif\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270731c3-4d7f-4c16-8686-912caa165d56",
   "metadata": {},
   "source": [
    "## Generacion de imagenes y poses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a7c6ea-8a99-4c36-baa0-0eaf3f9b6bfb",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/colmap.jpeg\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3d80b8-177d-41ed-a857-7a4336b80db2",
   "metadata": {},
   "source": [
    "cd instant-ngp\n",
    "python scripts/colmap2nerf.py --video_in ../input_video/ph_sample.mp4 --run_colmap --video_fps 10 --out ../input_video/transforms.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36dc191b-5f01-4912-967b-d092453a4357",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['camera_angle_x', 'camera_angle_y', 'fl_x', 'fl_y', 'k1', 'k2', 'p1', 'p2', 'cx', 'cy', 'w', 'h', 'aabb_scale', 'frames']\n",
      "\n",
      "{'file_path': './../input_video/images/0059.jpg', 'sharpness': 5.324371619065157, 'transform_matrix': [[-0.5652672847321779, 0.7578984785951647, -0.3256728312092346, -1.4420728940635466], [-0.5431733811820185, -0.04484349913168442, 0.8384221720534663, 3.8003048264697905], [0.6208345792962311, 0.6508294375429585, 0.43701884220330006, 1.7475136963027187], [0.0, 0.0, 0.0, 1.0]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "transforms_path = \"input_video/transforms.json\"\n",
    "with open(transforms_path) as ts:\n",
    "    transforms = json.load(ts)\n",
    "    \n",
    "print(list(transforms.keys()))\n",
    "print()\n",
    "print(transforms[\"frames\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d7968-b4a3-4b21-a7c2-c269d588edc7",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/ornothing.gif\"/></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeRF",
   "language": "python",
   "name": "nerf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
